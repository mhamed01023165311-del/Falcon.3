/// <reference types="vite/client" />
import React, { useState } from 'react';
import { Mic, Camera, Volume2, Loader2, Image as ImageIcon, RotateCcw } from 'lucide-react';
import { Camera as CapCamera, CameraResultType, CameraSource } from '@capacitor/camera';

const API_KEY = import.meta.env.VITE_GEMINI_KEY;

const VisualAssistant: React.FC = () => {
  const [image, setImage] = useState<string | null>(null);
  const [status, setStatus] = useState<string>("Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø¨ØµØ±ÙŠ. ØµÙˆØ± Ø£ÙŠ Ø´ÙŠØ¡ ÙˆØ³Ø£Ø®Ø¨Ø±Ùƒ Ù…Ø§ Ù‡Ùˆ.");
  const [isProcessing, setIsProcessing] = useState(false);
  const [isListening, setIsListening] = useState(false);

  // 1. Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© (Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ø£ØµÙ„ÙŠØ©)
  const captureImage = async () => {
    try {
      const photo = await CapCamera.getPhoto({
        quality: 60,
        allowEditing: false,
        resultType: CameraResultType.Base64,
        source: CameraSource.Camera, // ÙØªØ­ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ù„Ø£ØµÙ„ÙŠØ©
        width: 800 // Ø­Ø¬Ù… Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø³Ø±Ø¹Ø©
      });

      if (photo.base64String) {
        setImage(`data:image/jpeg;base64,${photo.base64String}`);
        processImage(photo.base64String, "ØµÙ Ù…Ø§ ØªØ±Ø§Ù‡ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„ØªÙØµÙŠÙ„ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.");
      }
    } catch (error) {
      console.error("Camera Error:", error);
      setStatus("Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø©.");
    }
  };

  // 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
  const processImage = async (base64: string, prompt: string) => {
    if (!API_KEY) { setStatus("Ø®Ø·Ø£: Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ÙÙ‚ÙˆØ¯."); return; }
    
    setIsProcessing(true);
    setStatus("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„... Ù„Ø­Ø¸Ø© ÙˆØ§Ø­Ø¯Ø© ðŸ§ ");

    try {
      const response = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${API_KEY}`,
        {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            contents: [{
              parts: [
                { text: prompt },
                { inline_data: { mime_type: "image/jpeg", data: base64 } }
              ]
            }]
          })
        }
      );

      const data = await response.json();
      if (!response.ok) throw new Error(data.error?.message);

      const text = data.candidates?.[0]?.content?.parts?.[0]?.text || "Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªÙ…ÙŠÙŠØ² Ø§Ù„ØµÙˆØ±Ø©.";
      
      setStatus(text);
      speak(text);

    } catch (error) {
      setStatus("Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø³ÙŠØ±ÙØ±.");
    } finally {
      setIsProcessing(false);
    }
  };

  // 3. Ø§Ù„Ù†Ø·Ù‚
  const speak = (text: string) => {
    window.speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ar-SA';
    window.speechSynthesis.speak(utterance);
  };

  // 4. Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ (Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©)
  const startListening = () => {
    if (!image) {
      setStatus("ÙŠØ¬Ø¨ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø£ÙˆÙ„Ø§Ù‹ Ù„ØªØ³Ø£Ù„ Ø¹Ù†Ù‡Ø§!");
      speak("ÙŠØ¬Ø¨ Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø© Ø£ÙˆÙ„Ø§Ù‹");
      return;
    }

    if (!('webkitSpeechRecognition' in window)) {
      alert("Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…ØŒ Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø©.");
      processImage(image.split(',')[1], "ØµÙ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰");
      return;
    }
    
    // @ts-ignore
    const recognition = new window.webkitSpeechRecognition();
    recognition.lang = 'ar-SA';
    recognition.start();
    setIsListening(true);
    setStatus("Ø£Ø³ØªÙ…Ø¹ Ø¥Ù„ÙŠÙƒ... Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø§Ù„ØµÙˆØ±Ø© ðŸŽ¤");

    recognition.onresult = (event: any) => {
      const question = event.results[0][0].transcript;
      setIsListening(false);
      setStatus(`Ø³Ø¤Ø§Ù„Ùƒ: "${question}"... Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«...`);
      // Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
      processImage(image.split(',')[1], `Ø£Ø¬Ø¨ Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø©: ${question}`);
    };

    recognition.onerror = () => {
      setIsListening(false);
      setStatus("Ù„Ù… Ø£Ø³Ù…Ø¹ Ø¬ÙŠØ¯Ø§Ù‹.");
    };
  };

  return (
    <div className="relative h-screen w-full bg-[#0f172a] text-white font-['Cairo'] flex flex-col overflow-hidden">
      
      {/* Ù…Ù†Ø·Ù‚Ø© Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© */}
      <div className="flex-1 relative m-4 rounded-[40px] overflow-hidden bg-slate-800 border-2 border-slate-700 shadow-2xl">
        {image ? (
          <img src={image} alt="Captured" className="w-full h-full object-cover" />
        ) : (
          <div className="absolute inset-0 flex flex-col items-center justify-center text-slate-500 bg-gradient-to-b from-slate-800 to-slate-900">
            <ImageIcon size={80} className="opacity-20 mb-4" />
            <p className="text-lg opacity-60">Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø©</p>
          </div>
        )}
        
        {/* Ø·Ø¨Ù‚Ø© Ø§Ù„ØªØ¹ØªÙŠÙ… Ù„Ù„Ù†Øµ */}
        <div className="absolute bottom-0 left-0 right-0 bg-gradient-to-t from-black/90 via-black/60 to-transparent p-6 pt-20">
           <div className="max-h-[150px] overflow-y-auto">
             <p className="text-lg font-bold text-center leading-relaxed dir-rtl text-blue-100">
               {status}
             </p>
           </div>
        </div>

        {isProcessing && (
          <div className="absolute inset-0 bg-black/60 flex items-center justify-center backdrop-blur-sm">
            <Loader2 size={60} className="text-blue-500 animate-spin" />
          </div>
        )}
      </div>

      {/* Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… */}
      <div className="h-[120px] bg-slate-900 rounded-t-[40px] shadow-[0_-5px_20px_rgba(0,0,0,0.5)] flex items-center justify-center gap-8 pb-4 relative z-20">
        
        {/* Ø²Ø± Ø§Ù„Ø³Ø¤Ø§Ù„ (Ø§Ù„Ù…Ø§ÙŠÙƒ) */}
        <button 
          onClick={startListening}
          disabled={isProcessing}
          className={`w-16 h-16 rounded-full flex items-center justify-center border-2 transition-all ${
            isListening 
              ? 'bg-red-500 border-red-400 animate-pulse' 
              : 'bg-slate-700 border-slate-600 hover:bg-slate-600'
          }`}
        >
          <Mic size={28} className="text-white" />
        </button>

        {/* Ø²Ø± Ø§Ù„ØªØµÙˆÙŠØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ */}
        <button 
          onClick={captureImage}
          disabled={isProcessing}
          className="w-24 h-24 rounded-full bg-blue-600 border-[6px] border-slate-900 flex items-center justify-center shadow-lg transform -translate-y-8 active:scale-95 transition-transform"
        >
          <Camera size={40} className="text-white" />
        </button>

        {/* Ø²Ø± Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø·Ù‚ */}
        <button 
          onClick={() => speak(status)}
          className="w-16 h-16 rounded-full flex items-center justify-center bg-slate-700 border-2 border-slate-600 hover:bg-slate-600 transition-all"
        >
          <Volume2 size={28} className="text-green-400" />
        </button>

      </div>
    </div>
  );
};

export default VisualAssistant;
