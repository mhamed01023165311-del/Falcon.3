/// <reference types="vite/client" />
import React, { useRef, useState, useEffect } from 'react';
import { Mic, Camera, Volume2, Loader2, RefreshCcw } from 'lucide-react';
import { Camera as CapCamera } from '@capacitor/camera'; // Ø§Ø³ØªÙŠØ±Ø§Ø¯ ÙƒØ§Ø¨Ø§ÙƒØªÙˆØ± Ù„Ù„Ø£Ø°ÙˆÙ†Ø§Øª

const API_KEY = import.meta.env.VITE_GEMINI_KEY;

const VisualAssistant: React.FC = () => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const [status, setStatus] = useState<string>("Ø£Ù‡Ù„Ø§Ù‹! Ø£Ù†Ø§ Ø¹ÙŠÙ†Ùƒ Ø§Ù„Ø°ÙƒÙŠØ©. Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù„Ø£ØµÙ Ù„Ùƒ Ù…Ø§ Ø£Ø±Ø§Ù‡.");
  const [isProcessing, setIsProcessing] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [cameraActive, setCameraActive] = useState(false);

  // 1. Ø·Ù„Ø¨ Ø§Ù„Ø£Ø°ÙˆÙ†Ø§Øª ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø¹Ù†Ø¯ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
  useEffect(() => {
    initCamera();
    return () => stopCamera();
  }, []);

  const initCamera = async () => {
    try {
      // Ø·Ù„Ø¨ Ø¥Ø°Ù† Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ø£ÙˆÙ„Ø§Ù‹
      const permissions = await CapCamera.requestPermissions({ permissions: ['camera'] });
      
      if (permissions.camera === 'granted') {
        startCameraStream();
      } else {
        setStatus("ÙŠØ¬Ø¨ Ø§Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù„ÙŠØ¹Ù…Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.");
      }
    } catch (e) {
      console.error("Permission Error:", e);
      // Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø­ØªÙ‰ Ù„Ùˆ ÙØ´Ù„ Ø·Ù„Ø¨ Ø§Ù„Ø¥Ø°Ù† (Ù„Ù„Ù…ØªØµÙØ­)
      startCameraStream();
    }
  };

  const startCameraStream = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'environment', width: { ideal: 1280 }, height: { ideal: 720 } }
      });
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        setCameraActive(true);
      }
    } catch (err) {
      console.error("Camera Error:", err);
      setStatus("ØªØ¹Ø°Ø± Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù„ÙƒØ§Ù…ÙŠØ±Ø§. ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø°ÙˆÙ†Ø§Øª.");
      setCameraActive(false);
    }
  };

  const stopCamera = () => {
    if (videoRef.current?.srcObject) {
      (videoRef.current.srcObject as MediaStream).getTracks().forEach(t => t.stop());
      setCameraActive(false);
    }
  };

  // 2. Ø§Ù„ØªÙ‚Ø§Ø· ØµÙˆØ±Ø©
  const captureFrame = (): string | null => {
    if (videoRef.current && canvasRef.current) {
      const video = videoRef.current;
      const canvas = canvasRef.current;
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      const ctx = canvas.getContext('2d');
      if (ctx) {
        ctx.drawImage(video, 0, 0);
        return canvas.toDataURL('image/jpeg', 0.5).split(',')[1];
      }
    }
    return null;
  };

  // 3. Ø§Ù„Ù†Ø·Ù‚
  const speak = (text: string) => {
    window.speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ar-SA';
    window.speechSynthesis.speak(utterance);
  };

  // 4. Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹
  const startListening = () => {
    if (!('webkitSpeechRecognition' in window)) {
      alert("Ù…ÙŠØ²Ø© Ø§Ù„ØµÙˆØª ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©ØŒ Ø³ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ù‡Ø¯ ÙÙ‚Ø·.");
      processRequest("ØµÙ Ù…Ø§ ØªØ±Ø§Ù‡");
      return;
    }
    
    // @ts-ignore
    const recognition = new window.webkitSpeechRecognition();
    recognition.lang = 'ar-SA';
    recognition.start();
    setIsListening(true);
    setStatus("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹... ğŸ¤");

    recognition.onresult = (event: any) => {
      const question = event.results[0][0].transcript;
      setIsListening(false);
      processRequest(question);
    };

    recognition.onerror = () => {
      setIsListening(false);
      setStatus("Ù„Ù… Ø£Ø³Ù…Ø¹Ùƒ Ø¬ÙŠØ¯Ø§Ù‹ØŒ Ø§Ø¶ØºØ· ÙˆØ­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.");
    };
  };

  // 5. Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
  const processRequest = async (question: string) => {
    if (isProcessing) return;
    const imageBase64 = captureFrame();
    
    if (!imageBase64) {
        setStatus("Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù„Ø§ ØªØ¹Ù…Ù„! Ø§Ø¶ØºØ· Ø²Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ«.");
        return;
    }
    if (!API_KEY) {
        setStatus("Ø®Ø·Ø£: Ù…ÙØªØ§Ø­ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ÙÙ‚ÙˆØ¯.");
        return;
    }

    setIsProcessing(true);
    setStatus(`.. Ø¬Ø§Ø±Ù Ø§Ù„ØªÙÙƒÙŠØ± ..`);

    try {
      const response = await fetch(
        `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key=${API_KEY}`,
        {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            contents: [{
              parts: [
                { text: `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¨ØµØ±ÙŠ Ù„Ù„Ù…ÙƒÙÙˆÙÙŠÙ†. Ø§Ù†Ø¸Ø± Ù„Ù„ØµÙˆØ±Ø© ÙˆØ£Ø¬Ø¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø®ØªØµØ§Ø± ÙˆÙ…ÙˆØ¯Ø©: "${question}"` },
                { inline_data: { mime_type: "image/jpeg", data: imageBase64 } }
              ]
            }]
          })
        }
      );

      const data = await response.json();
      const text = data.candidates?.[0]?.content?.parts?.[0]?.text || "Ù„Ù… Ø£Ø³ØªØ·Ø¹ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©.";
      
      setStatus(text);
      speak(text);

    } catch (error) {
      setStatus("Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„.");
    } finally {
      setIsProcessing(false);
    }
  };

  return (
    <div className="relative h-screen w-full bg-black overflow-hidden flex flex-col font-['Cairo'] text-white">
      
      {/* Ø·Ø¨Ù‚Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§) - ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© ØªÙ…Ø§Ù…Ø§Ù‹ */}
      <video 
        ref={videoRef} 
        autoPlay 
        playsInline 
        muted 
        className={`absolute inset-0 w-full h-full object-cover transition-opacity duration-500 ${cameraActive ? 'opacity-100' : 'opacity-0'}`} 
        style={{ zIndex: 0 }}
      />
      
      <canvas ref={canvasRef} className="hidden" />

      {/* Ø²Ø± Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ (ÙŠØ¸Ù‡Ø± ÙÙ‚Ø· Ù„Ùˆ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ø¹Ù„Ù‚Ø©) */}
      {!cameraActive && (
        <div className="absolute inset-0 flex flex-col items-center justify-center z-10 bg-gray-900">
            <button onClick={initCamera} className="flex flex-col items-center gap-4 text-blue-400">
                <RefreshCcw size={48} />
                <span className="text-xl font-bold">ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§</span>
            </button>
        </div>
      )}

      {/* Ø·Ø¨Ù‚Ø© ØªØ¸Ù„ÙŠÙ„ Ø®ÙÙŠÙØ© Ø¹Ø´Ø§Ù† Ø§Ù„ÙƒÙ„Ø§Ù… ÙŠØ¨Ø§Ù† */}
      <div className="absolute inset-0 bg-gradient-to-b from-black/70 via-transparent to-black/80 pointer-events-none z-10"></div>

      {/* Ø§Ù„Ù…Ø­ØªÙˆÙ‰ (ÙÙˆÙ‚ ÙƒÙ„ Ø´ÙŠØ¡ z-20) */}
      <div className="relative z-20 flex-1 flex flex-col justify-between p-6">
        
        {/* Ù…Ø±Ø¨Ø¹ Ø§Ù„Ù†Øµ (Ø§Ù„Ø±Ø¯) */}
        <div className="mt-12 bg-black/60 backdrop-blur-md p-6 rounded-3xl border border-white/20 text-center shadow-xl">
          <p className="text-lg md:text-2xl font-bold leading-relaxed dir-rtl">
            {status}
          </p>
        </div>

        {/* Ø§Ù„Ø£Ø²Ø±Ø§Ø± */}
        <div className="mb-8 flex justify-center items-center gap-8">
          
          {/* Ø²Ø± Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† */}
          <button 
            onClick={startListening}
            disabled={isProcessing}
            className={`w-16 h-16 rounded-full flex items-center justify-center bg-gray-800/80 border border-gray-600 active:scale-95 transition-all ${isListening ? 'bg-red-500/80 border-red-400 animate-pulse' : ''}`}
          >
            <Mic size={28} className="text-white" />
          </button>

          {/* Ø²Ø± Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ (Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ) */}
          <button 
            onClick={() => processRequest("ØµÙ Ù…Ø§ ØªØ±Ø§Ù‡ Ø£Ù…Ø§Ù…Ùƒ")}
            disabled={isProcessing}
            className="w-24 h-24 bg-white rounded-full flex items-center justify-center shadow-[0_0_40px_rgba(255,255,255,0.4)] active:scale-95 transition-transform border-4 border-blue-500"
          >
            {isProcessing ? (
              <Loader2 size={48} className="text-blue-600 animate-spin" />
            ) : (
              <div className="w-20 h-20 bg-blue-600 rounded-full flex items-center justify-center">
                  <Camera size={40} className="text-white" />
              </div>
            )}
          </button>

          {/* Ø²Ø± Ø§Ù„Ù†Ø·Ù‚ */}
          <button 
            onClick={() => speak(status)}
            className="w-16 h-16 rounded-full flex items-center justify-center bg-gray-800/80 border border-gray-600 active:scale-95 transition-all"
          >
            <Volume2 size={28} className="text-green-400" />
          </button>

        </div>
      </div>
    </div>
  );
};

export default VisualAssistant;
